{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "XHtaPysVSNZN"
   },
   "source": [
    "# Step 1 - Install the required dependencies and make sure the python version is 3.10 and above"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "APS6D3eiSAR_"
   },
   "outputs": [],
   "source": [
    "%pip install zenoml"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%pip install datasets\n",
    "%pip install transformers\n",
    "%pip install tqdm\n",
    "%pip install torch"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "CRrMiMnLV9xY",
    "outputId": "5193e819-f2cb-4032-99df-ced1ea7b4191",
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "!python --version"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Step 2 - Load a dataset from Hugging Face"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\djoc8\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.12_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python312\\site-packages\\tqdm\\auto.py:21: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>text</th>\n",
       "      <th>label</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>@user @user what do these '1/2 naked pics' hav...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>OH: ‚ÄúI had a blue penis while I was this‚Äù [pla...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>@user @user That's coming, but I think the vic...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>I think I may be finally in with the in crowd ...</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>@user Wow,first Hugo Chavez and now Fidel Cast...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                text  label\n",
       "0  @user @user what do these '1/2 naked pics' hav...      1\n",
       "1  OH: ‚ÄúI had a blue penis while I was this‚Äù [pla...      1\n",
       "2  @user @user That's coming, but I think the vic...      1\n",
       "3  I think I may be finally in with the in crowd ...      2\n",
       "4  @user Wow,first Hugo Chavez and now Fidel Cast...      0"
      ]
     },
     "execution_count": 1,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from datasets import load_dataset\n",
    "import pandas as pd\n",
    "\n",
    "ds = load_dataset(\"cardiffnlp/tweet_eval\", \"sentiment\")\n",
    "df = pd.DataFrame(ds['test']).head(500)\n",
    "df.head(5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "def label_map(x):\n",
    "    if x == 0:\n",
    "        return 'negative'\n",
    "    elif x == 1:\n",
    "        return 'neutral'\n",
    "    elif x == 2:\n",
    "        return 'positive'\n",
    "    return x\n",
    "df['label'] = df['label'].map(label_map)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Step 3 - Run model inference"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Warning: This step is going to download two models of ~500MB each. \n",
    "\n",
    "**If you don't want to download the models, you can jump to step 4 and use the provided data in the repo instead.**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Run inference with roberta"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# Use a pipeline as a high-level helper\n",
    "from transformers import pipeline\n",
    "\n",
    "pipe = pipeline(\"text-classification\", model=\"cardiffnlp/twitter-roberta-base-sentiment-latest\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import tqdm\n",
    "\n",
    "results = []\n",
    "texts = df['text'].to_list()\n",
    "\n",
    "## Depending on your machine, this should take around 1 minute\n",
    "for text in tqdm.tqdm(texts):\n",
    "    results.append(pipe(text))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "df['roberta'] = [r[0]['label'] for r in results]\n",
    "df['roberta_score'] = [r[0]['score'] for r in results]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Run inference with gpt2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Use a pipeline as a high-level helper\n",
    "from transformers import pipeline\n",
    "\n",
    "pipe = pipeline(\"text-classification\", model=\"LYTinn/finetuning-sentiment-model-tweet-gpt2\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import tqdm\n",
    "\n",
    "results = []\n",
    "texts = df['text'].to_list()\n",
    "\n",
    "## Depending on your machine, this should take around 1 minute\n",
    "for text in tqdm.tqdm(texts):\n",
    "    results.append(pipe(text))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "df['gpt2'] = [r[0]['label'] for r in results]\n",
    "df['gpt2_score'] = [r[0]['score'] for r in results]\n",
    "\n",
    "## map labels back\n",
    "def label_map(x):\n",
    "    if x == 'LABEL_0':\n",
    "        return 'negative'\n",
    "    elif x == 'LABEL_1':\n",
    "        return 'neutral'\n",
    "    elif x == 'LABEL_2':\n",
    "        return 'positive'\n",
    "    return x\n",
    "df['gpt2'] = df['gpt2'].map(label_map)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Step 4 - Pre-processing data and add additional columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "## If you skip the model inference, uncomment the code below and load the provided data\n",
    "\n",
    "# df = pd.read_csv('tweets.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "df[\"input_length\"] = df[\"text\"].str.len()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Step 5 - Start Zeno for interactive slicing\n",
    "\n",
    "In this step, you need to create 5 slices in the Zeno interface and derive meaningful insights.\n",
    "\n",
    "As a starting point, try to create the two slices we provide:\n",
    "\n",
    "1. Tweets with hashtags\n",
    "2. Tweets with strong positive words (e.g., love) -- you can determine the exact words"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Creating slices in Zeno is straightforward: Just click on the '+' button for 'create a new slice', and you can define the slice using existing column attributes, with simple value macthing or even regular expression.\n",
    "\n",
    "![image.png](images/image.png)\n",
    "\n",
    "There are more fun features in Zeno, including interactive metadata & model comparison -- feel free to check the teaser video in [README](https://github.com/zeno-ml/zeno) of the Zeno repository."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%pip install zeno_client"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Successfully created project.\n",
      "Access your project at  https://hub.zenoml.com/project/001f935d-a452-4288-8001-985882cf6f33/Tweet%20Sentiment%20Analysis\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\djoc8\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.12_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python312\\site-packages\\zeno_client\\util.py:25: FutureWarning: Setting an item of incompatible dtype is deprecated and will raise in a future error of pandas. Value '['0' '1' '2' '3' '4' '5' '6' '7' '8' '9' '10' '11' '12' '13' '14' '15'\n",
      " '16' '17' '18' '19' '20' '21' '22' '23' '24' '25' '26' '27' '28' '29'\n",
      " '30' '31' '32' '33' '34' '35' '36' '37' '38' '39' '40' '41' '42' '43'\n",
      " '44' '45' '46' '47' '48' '49' '50' '51' '52' '53' '54' '55' '56' '57'\n",
      " '58' '59' '60' '61' '62' '63' '64' '65' '66' '67' '68' '69' '70' '71'\n",
      " '72' '73' '74' '75' '76' '77' '78' '79' '80' '81' '82' '83' '84' '85'\n",
      " '86' '87' '88' '89' '90' '91' '92' '93' '94' '95' '96' '97' '98' '99'\n",
      " '100' '101' '102' '103' '104' '105' '106' '107' '108' '109' '110' '111'\n",
      " '112' '113' '114' '115' '116' '117' '118' '119' '120' '121' '122' '123'\n",
      " '124' '125' '126' '127' '128' '129' '130' '131' '132' '133' '134' '135'\n",
      " '136' '137' '138' '139' '140' '141' '142' '143' '144' '145' '146' '147'\n",
      " '148' '149' '150' '151' '152' '153' '154' '155' '156' '157' '158' '159'\n",
      " '160' '161' '162' '163' '164' '165' '166' '167' '168' '169' '170' '171'\n",
      " '172' '173' '174' '175' '176' '177' '178' '179' '180' '181' '182' '183'\n",
      " '184' '185' '186' '187' '188' '189' '190' '191' '192' '193' '194' '195'\n",
      " '196' '197' '198' '199' '200' '201' '202' '203' '204' '205' '206' '207'\n",
      " '208' '209' '210' '211' '212' '213' '214' '215' '216' '217' '218' '219'\n",
      " '220' '221' '222' '223' '224' '225' '226' '227' '228' '229' '230' '231'\n",
      " '232' '233' '234' '235' '236' '237' '238' '239' '240' '241' '242' '243'\n",
      " '244' '245' '246' '247' '248' '249' '250' '251' '252' '253' '254' '255'\n",
      " '256' '257' '258' '259' '260' '261' '262' '263' '264' '265' '266' '267'\n",
      " '268' '269' '270' '271' '272' '273' '274' '275' '276' '277' '278' '279'\n",
      " '280' '281' '282' '283' '284' '285' '286' '287' '288' '289' '290' '291'\n",
      " '292' '293' '294' '295' '296' '297' '298' '299' '300' '301' '302' '303'\n",
      " '304' '305' '306' '307' '308' '309' '310' '311' '312' '313' '314' '315'\n",
      " '316' '317' '318' '319' '320' '321' '322' '323' '324' '325' '326' '327'\n",
      " '328' '329' '330' '331' '332' '333' '334' '335' '336' '337' '338' '339'\n",
      " '340' '341' '342' '343' '344' '345' '346' '347' '348' '349' '350' '351'\n",
      " '352' '353' '354' '355' '356' '357' '358' '359' '360' '361' '362' '363'\n",
      " '364' '365' '366' '367' '368' '369' '370' '371' '372' '373' '374' '375'\n",
      " '376' '377' '378' '379' '380' '381' '382' '383' '384' '385' '386' '387'\n",
      " '388' '389' '390' '391' '392' '393' '394' '395' '396' '397' '398' '399'\n",
      " '400' '401' '402' '403' '404' '405' '406' '407' '408' '409' '410' '411'\n",
      " '412' '413' '414' '415' '416' '417' '418' '419' '420' '421' '422' '423'\n",
      " '424' '425' '426' '427' '428' '429' '430' '431' '432' '433' '434' '435'\n",
      " '436' '437' '438' '439' '440' '441' '442' '443' '444' '445' '446' '447'\n",
      " '448' '449' '450' '451' '452' '453' '454' '455' '456' '457' '458' '459'\n",
      " '460' '461' '462' '463' '464' '465' '466' '467' '468' '469' '470' '471'\n",
      " '472' '473' '474' '475' '476' '477' '478' '479' '480' '481' '482' '483'\n",
      " '484' '485' '486' '487' '488' '489' '490' '491' '492' '493' '494' '495'\n",
      " '496' '497' '498' '499']' has dtype incompatible with int64, please explicitly cast to a compatible dtype first.\n",
      "  df.loc[:, id_column] = df[id_column].astype(str)\n",
      "100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 1/1 [00:01<00:00,  1.26s/it]\n",
      "C:\\Users\\djoc8\\AppData\\Local\\Temp\\ipykernel_5136\\4235081219.py:25: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  df_system[\"correct\"] = (df_system[model] == df[\"label\"]).astype(int)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Successfully uploaded data\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 1/1 [00:00<00:00,  1.26it/s]\n",
      "C:\\Users\\djoc8\\AppData\\Local\\Temp\\ipykernel_5136\\4235081219.py:25: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  df_system[\"correct\"] = (df_system[model] == df[\"label\"]).astype(int)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Successfully uploaded system\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 1/1 [00:00<00:00,  1.32it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Successfully uploaded system\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "from zeno_client import ZenoClient, ZenoMetric\n",
    "import pandas as pd\n",
    "\n",
    "df = pd.read_csv('tweets.csv')\n",
    "df = df.reset_index()\n",
    "\n",
    "# Initialize a client with the API key.\n",
    "client = ZenoClient('zen_86R3sKvKLptA6EizL7oLs-tm-iEzwoHk5ZE1SqQU-Vo')\n",
    "\n",
    "project = client.create_project(\n",
    "    name=\"Tweet Sentiment Analysis\",\n",
    "    view=\"text-classification\",\n",
    "    metrics=[\n",
    "        ZenoMetric(name=\"accuracy\", type=\"mean\", columns=[\"correct\"]),\n",
    "    ]\n",
    ")\n",
    "\n",
    "project.upload_dataset(df, id_column=\"index\", data_column=\"text\", label_column=\"label\")\n",
    "\n",
    "models = ['roberta', 'gpt2']\n",
    "for model in models:\n",
    "    df_system = df[['index', model]]\n",
    "    \n",
    "    # Measure accuracy for each instance, which is averaged by the ZenoMetric above\n",
    "    df_system[\"correct\"] = (df_system[model] == df[\"label\"]).astype(int)\n",
    "    \n",
    "    project.upload_system(df_system, name=model, id_column=\"index\", output_column=model)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "After running the code above, you should be able to access Zeno in http://localhost:8231"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "After successfully creating the two slices, come up with three *additional* slices you want to check and **create** the slices in the Zeno interface.\n",
    "\n",
    "There are two directions to identify useful slices:\n",
    "- Top-down: Think about what kinds of things the model can struggle with, and come up with some slices.\n",
    "- Bottom-up: Look at model (mis-)predictions, come up with hypotheses, and translate them into data slices.\n",
    "\n",
    "3. [YOUR CHOICE]\n",
    "4. [YOUR CHOICE]\n",
    "5. [YOUR CHOICE]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Defaulting to user installation because normal site-packages is not writeable\n",
      "Collecting emoji\n",
      "  Downloading emoji-2.14.1-py3-none-any.whl.metadata (5.7 kB)\n",
      "Downloading emoji-2.14.1-py3-none-any.whl (590 kB)\n",
      "   ---------------------------------------- 0.0/590.6 kB ? eta -:--:--\n",
      "   ---------------------------------------- 590.6/590.6 kB 7.0 MB/s eta 0:00:00\n",
      "Installing collected packages: emoji\n",
      "Successfully installed emoji-2.14.1\n",
      "Note: you may need to restart the kernel to use updated packages.\n"
     ]
    }
   ],
   "source": [
    "%pip install emoji"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "## Write down descriptions of additional slices you created\n",
    "\n",
    "custom_slice_descriptions = [\n",
    "    \"Tweets that contain emojis.\",\n",
    "    \"Tweets that contain mentions (i.e., '@' symbol).\", \n",
    "    \"Tweets Equal to 140 Length\",\n",
    "]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import emoji\n",
    "\n",
    "def contiene_emoji(texto):\n",
    "    return any(char in emoji.EMOJI_DATA for char in texto)\n",
    "\n",
    "df1 = pd.read_csv('tweets.csv')\n",
    "df1 = df1.reset_index()\n",
    "\n",
    "df1['Tiene_Emoji'] = df1['text'].apply(contiene_emoji)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>index</th>\n",
       "      <th>text</th>\n",
       "      <th>label</th>\n",
       "      <th>roberta</th>\n",
       "      <th>roberta_score</th>\n",
       "      <th>input_length</th>\n",
       "      <th>gpt2</th>\n",
       "      <th>gpt2_score</th>\n",
       "      <th>Tiene_Emoji</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>@user @user what do these '1/2 naked pics' hav...</td>\n",
       "      <td>neutral</td>\n",
       "      <td>negative</td>\n",
       "      <td>0.804726</td>\n",
       "      <td>96</td>\n",
       "      <td>positive</td>\n",
       "      <td>0.913451</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1</td>\n",
       "      <td>OH: ‚ÄúI had a blue penis while I was this‚Äù [pla...</td>\n",
       "      <td>neutral</td>\n",
       "      <td>neutral</td>\n",
       "      <td>0.866949</td>\n",
       "      <td>72</td>\n",
       "      <td>neutral</td>\n",
       "      <td>0.753405</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2</td>\n",
       "      <td>@user @user That's coming, but I think the vic...</td>\n",
       "      <td>neutral</td>\n",
       "      <td>neutral</td>\n",
       "      <td>0.763724</td>\n",
       "      <td>87</td>\n",
       "      <td>positive</td>\n",
       "      <td>0.999962</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>3</td>\n",
       "      <td>I think I may be finally in with the in crowd ...</td>\n",
       "      <td>positive</td>\n",
       "      <td>positive</td>\n",
       "      <td>0.774047</td>\n",
       "      <td>83</td>\n",
       "      <td>positive</td>\n",
       "      <td>0.898784</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>4</td>\n",
       "      <td>@user Wow,first Hugo Chavez and now Fidel Cast...</td>\n",
       "      <td>negative</td>\n",
       "      <td>neutral</td>\n",
       "      <td>0.416397</td>\n",
       "      <td>133</td>\n",
       "      <td>positive</td>\n",
       "      <td>0.986431</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>5</td>\n",
       "      <td>Savchenko now Saakashvili took drug test live ...</td>\n",
       "      <td>neutral</td>\n",
       "      <td>neutral</td>\n",
       "      <td>0.496369</td>\n",
       "      <td>103</td>\n",
       "      <td>negative</td>\n",
       "      <td>0.999930</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>6</td>\n",
       "      <td>How many more days until opening day? üò©</td>\n",
       "      <td>neutral</td>\n",
       "      <td>neutral</td>\n",
       "      <td>0.466571</td>\n",
       "      <td>39</td>\n",
       "      <td>negative</td>\n",
       "      <td>0.999988</td>\n",
       "      <td>True</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>7</td>\n",
       "      <td>Twitter's #ThankYouObama Shows Heartfelt Grati...</td>\n",
       "      <td>positive</td>\n",
       "      <td>positive</td>\n",
       "      <td>0.947964</td>\n",
       "      <td>59</td>\n",
       "      <td>positive</td>\n",
       "      <td>0.999593</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>8</td>\n",
       "      <td>All CSG and Fracking all around Australia is t...</td>\n",
       "      <td>neutral</td>\n",
       "      <td>negative</td>\n",
       "      <td>0.515992</td>\n",
       "      <td>112</td>\n",
       "      <td>positive</td>\n",
       "      <td>0.999992</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>9</td>\n",
       "      <td>@user @user @user @user @user @user take away ...</td>\n",
       "      <td>negative</td>\n",
       "      <td>neutral</td>\n",
       "      <td>0.646297</td>\n",
       "      <td>103</td>\n",
       "      <td>positive</td>\n",
       "      <td>0.792283</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>10</td>\n",
       "      <td>An interesting security vulnerability - albeit...</td>\n",
       "      <td>neutral</td>\n",
       "      <td>neutral</td>\n",
       "      <td>0.580255</td>\n",
       "      <td>77</td>\n",
       "      <td>positive</td>\n",
       "      <td>0.999925</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>11</td>\n",
       "      <td>#GilmoreGirlsTop4 1. Spoke2. Paris3. Emily4. P...</td>\n",
       "      <td>neutral</td>\n",
       "      <td>neutral</td>\n",
       "      <td>0.797165</td>\n",
       "      <td>77</td>\n",
       "      <td>neutral</td>\n",
       "      <td>0.999899</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>12</td>\n",
       "      <td>#onedirection #harrystyles cute little dance üòâ</td>\n",
       "      <td>positive</td>\n",
       "      <td>positive</td>\n",
       "      <td>0.900745</td>\n",
       "      <td>46</td>\n",
       "      <td>positive</td>\n",
       "      <td>0.996944</td>\n",
       "      <td>True</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13</th>\n",
       "      <td>13</td>\n",
       "      <td>When Ryan privatizes SS, Medicare, Medicaid, &amp;...</td>\n",
       "      <td>negative</td>\n",
       "      <td>negative</td>\n",
       "      <td>0.590688</td>\n",
       "      <td>140</td>\n",
       "      <td>neutral</td>\n",
       "      <td>0.999997</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14</th>\n",
       "      <td>14</td>\n",
       "      <td>Swampbitch Nasty Pelosi  loves yelling 'Fire' ...</td>\n",
       "      <td>negative</td>\n",
       "      <td>negative</td>\n",
       "      <td>0.843244</td>\n",
       "      <td>86</td>\n",
       "      <td>positive</td>\n",
       "      <td>0.742863</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15</th>\n",
       "      <td>15</td>\n",
       "      <td>@user ohhh ok i see ü§î what if u have medical m...</td>\n",
       "      <td>neutral</td>\n",
       "      <td>neutral</td>\n",
       "      <td>0.927514</td>\n",
       "      <td>93</td>\n",
       "      <td>positive</td>\n",
       "      <td>0.999991</td>\n",
       "      <td>True</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>16</th>\n",
       "      <td>16</td>\n",
       "      <td>OPINION: The Anti-#Trump #Riots Are a #SmokeSc...</td>\n",
       "      <td>neutral</td>\n",
       "      <td>negative</td>\n",
       "      <td>0.589598</td>\n",
       "      <td>51</td>\n",
       "      <td>neutral</td>\n",
       "      <td>0.999957</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>17</th>\n",
       "      <td>17</td>\n",
       "      <td>ISIS and The CIA What You Need To Know! #ISIS ...</td>\n",
       "      <td>neutral</td>\n",
       "      <td>negative</td>\n",
       "      <td>0.826902</td>\n",
       "      <td>84</td>\n",
       "      <td>neutral</td>\n",
       "      <td>0.999988</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>18</th>\n",
       "      <td>18</td>\n",
       "      <td>@user alt-right was adopted by Deplorables. Av...</td>\n",
       "      <td>neutral</td>\n",
       "      <td>neutral</td>\n",
       "      <td>0.515135</td>\n",
       "      <td>107</td>\n",
       "      <td>positive</td>\n",
       "      <td>0.999933</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>19</th>\n",
       "      <td>19</td>\n",
       "      <td>@user #GilmoreGirlsTop4 Lorelai, Rory, Lane, S...</td>\n",
       "      <td>neutral</td>\n",
       "      <td>neutral</td>\n",
       "      <td>0.886954</td>\n",
       "      <td>63</td>\n",
       "      <td>positive</td>\n",
       "      <td>0.999973</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>20</th>\n",
       "      <td>20</td>\n",
       "      <td>Christians In Palestine: Yes, They Exist #gaza...</td>\n",
       "      <td>neutral</td>\n",
       "      <td>neutral</td>\n",
       "      <td>0.746894</td>\n",
       "      <td>70</td>\n",
       "      <td>neutral</td>\n",
       "      <td>0.538679</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>21</th>\n",
       "      <td>21</td>\n",
       "      <td>@user Going to see #FantasticBeasts this after...</td>\n",
       "      <td>positive</td>\n",
       "      <td>positive</td>\n",
       "      <td>0.753966</td>\n",
       "      <td>125</td>\n",
       "      <td>positive</td>\n",
       "      <td>0.999726</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>22</th>\n",
       "      <td>22</td>\n",
       "      <td>Listen to win passes to see #FantasticBeasts a...</td>\n",
       "      <td>neutral</td>\n",
       "      <td>positive</td>\n",
       "      <td>0.568717</td>\n",
       "      <td>63</td>\n",
       "      <td>positive</td>\n",
       "      <td>0.971679</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>23</th>\n",
       "      <td>23</td>\n",
       "      <td>The United Nations Headquarters in New York #u...</td>\n",
       "      <td>neutral</td>\n",
       "      <td>neutral</td>\n",
       "      <td>0.792349</td>\n",
       "      <td>93</td>\n",
       "      <td>positive</td>\n",
       "      <td>0.999131</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>24</th>\n",
       "      <td>24</td>\n",
       "      <td>Zac Efron Flaunts Fit Abs in New ‚ÄòDirty Grandp...</td>\n",
       "      <td>neutral</td>\n",
       "      <td>neutral</td>\n",
       "      <td>0.607079</td>\n",
       "      <td>61</td>\n",
       "      <td>neutral</td>\n",
       "      <td>0.998811</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "    index                                               text     label  \\\n",
       "0       0  @user @user what do these '1/2 naked pics' hav...   neutral   \n",
       "1       1  OH: ‚ÄúI had a blue penis while I was this‚Äù [pla...   neutral   \n",
       "2       2  @user @user That's coming, but I think the vic...   neutral   \n",
       "3       3  I think I may be finally in with the in crowd ...  positive   \n",
       "4       4  @user Wow,first Hugo Chavez and now Fidel Cast...  negative   \n",
       "5       5  Savchenko now Saakashvili took drug test live ...   neutral   \n",
       "6       6            How many more days until opening day? üò©   neutral   \n",
       "7       7  Twitter's #ThankYouObama Shows Heartfelt Grati...  positive   \n",
       "8       8  All CSG and Fracking all around Australia is t...   neutral   \n",
       "9       9  @user @user @user @user @user @user take away ...  negative   \n",
       "10     10  An interesting security vulnerability - albeit...   neutral   \n",
       "11     11  #GilmoreGirlsTop4 1. Spoke2. Paris3. Emily4. P...   neutral   \n",
       "12     12     #onedirection #harrystyles cute little dance üòâ  positive   \n",
       "13     13  When Ryan privatizes SS, Medicare, Medicaid, &...  negative   \n",
       "14     14  Swampbitch Nasty Pelosi  loves yelling 'Fire' ...  negative   \n",
       "15     15  @user ohhh ok i see ü§î what if u have medical m...   neutral   \n",
       "16     16  OPINION: The Anti-#Trump #Riots Are a #SmokeSc...   neutral   \n",
       "17     17  ISIS and The CIA What You Need To Know! #ISIS ...   neutral   \n",
       "18     18  @user alt-right was adopted by Deplorables. Av...   neutral   \n",
       "19     19  @user #GilmoreGirlsTop4 Lorelai, Rory, Lane, S...   neutral   \n",
       "20     20  Christians In Palestine: Yes, They Exist #gaza...   neutral   \n",
       "21     21  @user Going to see #FantasticBeasts this after...  positive   \n",
       "22     22  Listen to win passes to see #FantasticBeasts a...   neutral   \n",
       "23     23  The United Nations Headquarters in New York #u...   neutral   \n",
       "24     24  Zac Efron Flaunts Fit Abs in New ‚ÄòDirty Grandp...   neutral   \n",
       "\n",
       "     roberta  roberta_score  input_length      gpt2  gpt2_score  Tiene_Emoji  \n",
       "0   negative       0.804726            96  positive    0.913451        False  \n",
       "1    neutral       0.866949            72   neutral    0.753405        False  \n",
       "2    neutral       0.763724            87  positive    0.999962        False  \n",
       "3   positive       0.774047            83  positive    0.898784        False  \n",
       "4    neutral       0.416397           133  positive    0.986431        False  \n",
       "5    neutral       0.496369           103  negative    0.999930        False  \n",
       "6    neutral       0.466571            39  negative    0.999988         True  \n",
       "7   positive       0.947964            59  positive    0.999593        False  \n",
       "8   negative       0.515992           112  positive    0.999992        False  \n",
       "9    neutral       0.646297           103  positive    0.792283        False  \n",
       "10   neutral       0.580255            77  positive    0.999925        False  \n",
       "11   neutral       0.797165            77   neutral    0.999899        False  \n",
       "12  positive       0.900745            46  positive    0.996944         True  \n",
       "13  negative       0.590688           140   neutral    0.999997        False  \n",
       "14  negative       0.843244            86  positive    0.742863        False  \n",
       "15   neutral       0.927514            93  positive    0.999991         True  \n",
       "16  negative       0.589598            51   neutral    0.999957        False  \n",
       "17  negative       0.826902            84   neutral    0.999988        False  \n",
       "18   neutral       0.515135           107  positive    0.999933        False  \n",
       "19   neutral       0.886954            63  positive    0.999973        False  \n",
       "20   neutral       0.746894            70   neutral    0.538679        False  \n",
       "21  positive       0.753966           125  positive    0.999726        False  \n",
       "22  positive       0.568717            63  positive    0.971679        False  \n",
       "23   neutral       0.792349            93  positive    0.999131        False  \n",
       "24   neutral       0.607079            61   neutral    0.998811        False  "
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df1.head(25)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Step 6 - Write down three addition data slices you want to create but do not have the metadata for slicing"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In the previous step, you might have already come up with some slices you wanted to create but found it hard to do with existing metadata. Write down three of such slices in this step.\n",
    "\n",
    "Example: \n",
    "- I want to create a slice on tweets using slangs\n",
    "- I want to create a slice on non-English tweets (if any)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "## Write down three additional data slices here:\n",
    "\n",
    "additional_slice_descriptions = [\n",
    "    \"I want to create a slice on tweets with URLs\",\n",
    "    \"I want to create a slice on tweets using bad words\",\n",
    "    \"I want to create a slice on political tweets\",\n",
    "]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Step 7 - Generate more test cases with Large Language Models"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Select one slice from the three you wrote down and generate **10 test cases** using LLMs, which can include average case, boundary case, or difficult case.\n",
    "\n",
    "Your input can be in the following format:\n",
    "\n",
    "> Examples:\n",
    "> - OH: ‚ÄúI had a blue penis while I was this‚Äù [playing with Google Earth VR]\n",
    "> - @user @user That‚Äôs coming, but I think the victims are going to be Medicaid recipients.\n",
    "> - I think I may be finally in with the in crowd #mannequinchallenge  #grads2014 @user\n",
    "> \n",
    "> Generate more tweets using slangs.\n",
    "\n",
    "The first part of **Examples** conditions the LLM on the style, length, and content of examples. The second part of **Instructions** instructs what kind of examples you want LLM to generate.\n",
    "\n",
    "Use our provided GPTs to start the task: [llm-based-test-case-generator](https://chatgpt.com/g/g-982cylVn2-llm-based-test-case-generator). If you do not have access to GPTs, use the plain ChatGPT or other LLM providers you have access to instead."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "## Write down the slice you select\n",
    "\n",
    "slice_description = \"Tweets that contain mentions (i.e., '@' symbol).\"\n",
    "\n",
    "## Write down all generated test cases here\n",
    "#generate **10 test cases** using LLMs, which can include average case, boundary case, or difficult case\n",
    "\n",
    "generated_test_cases = [\n",
    "    # Average cases\n",
    "    \"Hey @user, how are you doing today?\",\n",
    "    \"Check out this cool article by @tech_writer!\",\n",
    "    \"Had a great time at the event with @friend1 and @friend2.\",\n",
    "    \n",
    "    # Boundary cases\n",
    "    \"@user\",\n",
    "    \"Hello @user!\",\n",
    "    \"This is a test tweet without any mentions.\",\n",
    "    \n",
    "    # Difficult cases\n",
    "    \"Email me at user@example.com\",\n",
    "    \"Follow us on Twitter @company_handle for updates!\",\n",
    "    \"Is this a mention? @\",\n",
    "    \"Multiple mentions in one tweet: @user1 @user2 @user3\"\n",
    "]"
   ]
  }
 ],
 "metadata": {
  "colab": {
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
